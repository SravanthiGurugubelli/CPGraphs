{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGpdtJ2IPxdI"
      },
      "source": [
        "!pip install pulp\n",
        "!pip install skggm\n",
        "from sklearn.covariance import GraphicalLasso as glasso\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import pulp\n",
        "from numba import jit, cuda\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.metrics import f1_score\n",
        "from scipy.sparse import csr_matrix\n",
        "from time import time \n",
        "from six.moves import xrange\n",
        "from inverse_covariance import QuicGraphicalLasso\n",
        "import networkx as nx\n",
        "from sklearn import preprocessing\n",
        "from scipy.optimize import linprog\n",
        "from cvxopt import matrix\n",
        "from cvxopt import glpk\n",
        "from scipy.spatial.distance import pdist\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse.linalg import eigs\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#change 'sklearn.utils.testing' to 'sklearn.utils._testing\n",
        "#Add:\n",
        "#import joblib\n",
        "#sys.modules['sklearn.externals.joblib'] = joblib\n",
        "\n",
        "import pickle\n",
        "def save_variable(variable,filename):\n",
        "  pickle.dump(variable,open(filename, \"wb\"))\n",
        "def load_variable(filename):\n",
        "  return pickle.load(open(filename,'rb')) \n",
        "\n",
        "def NormalizeData(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThSKOQaihNF3"
      },
      "source": [
        "def UpdateTheta(X,alpha):\n",
        "  glasso_out = QuicGraphicalLasso(lam=alpha, tol=1e-0).fit(X)\n",
        "  theta = glasso_out.precision_\n",
        "  return theta\n",
        "\n",
        "def UpdateC(A,D):\n",
        "  Lp_prob = pulp.LpProblem('UpdateCe', pulp.LpMaximize)  \n",
        "  var_names = ['var_' + str(i) for i in range(np.size(A,0))]\n",
        "  C = [pulp.LpVariable(i, lowBound=0, upBound=1) for i in var_names]\n",
        "  Lp_prob += 2*np.sum(abs(A)@C)\n",
        "  ones_mat = np.ones((N,N))\n",
        "  for i in range(N):\n",
        "    for j in range(N):\n",
        "      Lp_prob += -(C[i]+C[j]) >= -1-e*logD[i,j] # Constraints\n",
        "  Lp_prob += (np.sum(C) == N/8) # Constraints\n",
        "\n",
        "  \n",
        "  status = Lp_prob.solve()   # Solver\n",
        "  C_out = np.zeros((N,))\n",
        "  for i in range(N):\n",
        "   C_out[i] = C[i].varValue\n",
        "\n",
        "  return C_out  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading data:\n",
        "\n",
        "#C.elegans\n",
        "data = loadmat('/Datasets/Celegans.mat')\n",
        "A0=np.array(data['A0'].todense())\n",
        "N=len(A0[:,0])\n",
        "coords = data['coords']\n",
        "X = data['coords'].T\n",
        "logD = np.zeros((N,N))\n",
        "for i in range(N):\n",
        "  for j in range(N):\n",
        "    logD[i,j] = 0.09*np.log(1000*(np.linalg.norm(coords[i,0:2]-coords[j,0:2])**2+0.001))\n",
        "\n",
        "'''\n",
        "#London underground\n",
        "data = loadmat('/Datasets/London_underground.mat')\n",
        "A0=np.array(data['A0'])\n",
        "N=len(A0[:,0])\n",
        "coords = data['Coords']\n",
        "X = data['Coords'].T\n",
        "logD = np.zeros((N,N))\n",
        "for i in range(N):\n",
        "  for j in range(N):\n",
        "    logD[i,j] = 0.09*np.log(1000*(np.linalg.norm(coords[i,0:2]-coords[j,0:2])**2+0.001))\n",
        "\n",
        "# Synthetic data\n",
        "A0 = load_variable('/Datasets/syn/theta_syn')\n",
        "N = np.size(A0,0)\n",
        "X = load_variable('/Datasets/syn/X_ao')\n",
        "D = np.size(X,1)\n",
        "elogD = load_variable('/Datasets/syn/elogD_syn')    \n",
        "c_true = load_variable('/Datasets/syn/c_syn')   \n",
        "'''"
      ],
      "metadata": {
        "id": "FRh3uHWq-EoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amZ7-6ztbYU9"
      },
      "source": [
        "C = 0.1*np.ones((N,)) # initialize core scores\n",
        "e = 0.1\n",
        "alpha = 0.1\n",
        "max_iter = 30\n",
        "alpha_ = np.ones((N,N))\n",
        "\n",
        "for m in range (0,max_iter):   \n",
        "  #Update Theta-----------------------------------------------------------------\n",
        "    for i in range (0,N):\n",
        "      for j in range (i,N):\n",
        "        alpha_aux = alpha*(1-C[i]-C[j]+e*logD[i,j]) \n",
        "        alpha_[i,j] = alpha_aux\n",
        "        alpha_[j,i] = alpha_aux  \n",
        "    theta = UpdateTheta(X, alpha_)\n",
        "    A = np.diag(np.diag(theta))-theta\n",
        "    print(\"A=\",A)\n",
        "\n",
        "  #Update C---------------------------------------------------------------------\n",
        "    C = UpdateC(theta,logD)\n",
        "    print(\"C=\",C)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}