{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGmbuEJ-Eexk",
        "outputId": "261abdb9-1cd8-4b69-ff55-0196c07c2b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygsp\n",
            "  Downloading PyGSP-0.5.1-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pygsp) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pygsp) (1.7.3)\n",
            "Installing collected packages: pygsp\n",
            "Successfully installed pygsp-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pygsp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OGpdtJ2IPxdI"
      },
      "outputs": [],
      "source": [
        "from sklearn.covariance import GraphicalLasso as glasso\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from time import time \n",
        "import networkx as nx\n",
        "import pygsp\n",
        "from sklearn import preprocessing\n",
        "from scipy.optimize import linprog\n",
        "from scipy.spatial.distance import pdist\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse.linalg import eigs\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
        "from scipy.optimize import bisect\n",
        "from scipy import sparse\n",
        "from scipy.special import expit\n",
        "from scipy.spatial.distance import cosine\n",
        "#import cvxpy as cp\n",
        "#from cvxpy.atoms.elementwise import logistic\n",
        "from sympy import *\n",
        "import pickle\n",
        "import timeit\n",
        "def save_variable(variable,filename):\n",
        "  pickle.dump(variable,open(filename, \"wb\"))\n",
        "def load_variable(filename):\n",
        "  return pickle.load(open(filename,'rb')) \n",
        "def NormalizeData(data):\n",
        "  X_std = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "  X_scaled = X_std * (1 - 0) + 1\n",
        "  return X_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "code",
        "id": "0vPnnbzqqAxY"
      },
      "outputs": [],
      "source": [
        "def UpdateW(X,Q,c,beta1,beta2,max_iter,rho_w,w_init):\n",
        "  w = w_init\n",
        "  N = len(X[:,0])\n",
        "  D = len(X[0,:])\n",
        "  c.shape = (N,1)\n",
        "  w.shape = (D,2)\n",
        "  B1 = X.T@np.append(c,np.ones((N,1)),1)-beta2*w\n",
        "  for j in range(max_iter):\n",
        "    Q = expit(np.append(c,np.ones((N,1)),axis=1)@w.T)\n",
        "    w = w + rho_w*(B1-Q.T@np.append(c,np.ones((N,1)),1))  \n",
        "    if (sum(sum((B1-Q.T@np.append(c,np.ones((N,1)),1))<1.0e-4*np.ones((len(X[0,:]),2))))==2*len(X[0,:])):\n",
        "      print('w Converged')\n",
        "      break\n",
        "  return Q,w\n",
        "\n",
        "def UpdateC(X,Q,w,abstheta,rho_c,c_init,max_iter,m,beta1):\n",
        "  c = c_init\n",
        "  N = len(X[:,0])\n",
        "  D = len(X[0,:])\n",
        "  obj = []\n",
        "  c.shape = (N,1)\n",
        "  w_ = w[:,0]\n",
        "  w_.shape = (D,1)\n",
        "  A1 = (abstheta@np.ones((N,1)))+X@w_\n",
        "  for j in range(max_iter):\n",
        "    Q = expit(np.append(c,np.ones((N,1)),axis=1)@w.T)\n",
        "    c = c + rho_c*(A1-Q@w_)\n",
        "\n",
        "    def f(x):\n",
        "      return sum([min(max(c[k]-x,0),1) for k in range(N)])-m   \n",
        "    lamda =  bisect(f,-10000,10000) \n",
        "\n",
        "    for i in        range(N):\n",
        "      c[i] = min(max(c[i]-lamda,0),1) \n",
        "    obj.append(sum(abs(A0)@c)+beta1*(sum(sum(X*np.log(Q+0.001)))+sum(sum((np.ones(np.shape(X))-X)*np.log(np.ones(np.shape(X))-Q+0.001)))))\n",
        "    if j>1:\n",
        "      if (abs(obj[j]-obj[j-1])<1.0e-4): \n",
        "        print('c Converged')\n",
        "        break  \n",
        "  return Q,c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uvil8NKDDXc"
      },
      "outputs": [],
      "source": [
        "# Loading data:\n",
        "\n",
        "# Facebook\n",
        "f = open(\"/content/drive/MyDrive/datasets/journal/fb/0.edges\")\n",
        "Lines = f.readlines()\n",
        "edges = []\n",
        "for line in Lines:\n",
        "   edges.append(line.split(\" \"))\n",
        "f.close()\n",
        "A_=np.zeros(np.shape(edges))\n",
        "for i in range(len(edges)):\n",
        "  for j in range(len(edges[0])):\n",
        "    A_[i,j] = int(edges[i][j])-1\n",
        "A0_ = A_ \n",
        "\n",
        "f = open(\"/content/drive/MyDrive/datasets/journal/fb/0.feat\")\n",
        "Lines = f.readlines()\n",
        "X_ = []\n",
        "for line in Lines:\n",
        "  X_.append(line.split(\" \"))\n",
        "f.close()\n",
        "X__=np.zeros(np.shape(X_))\n",
        "for i in range(len(X_)):\n",
        "  for j in range(len(X_[0])):\n",
        "    X__[i,j] = float(X_[i][j])\n",
        "\n",
        "X = X__[:,1:len(X__[0,:])]\n",
        "N=len(X[:,0])\n",
        "A0 = sparse.csr_matrix((np.ones(len(A0_[:,0])), (A0_[:,0], A0_[:,1])), shape=(N, N)).toarray()\n",
        "\n",
        "'''\n",
        "To load the other datasets in the paper:\n",
        "\n",
        "# Twitter\n",
        "data=loadmat('/Datasets/twitter/twitter.mat')\n",
        "A0 = np.array(data['A0'].todense())\n",
        "X = data['X']\n",
        "N = len(A0[:,0])\n",
        "\n",
        "\n",
        "# Gplus\n",
        "data=loadmat('/Datasets/gplus/gplus.mat')\n",
        "A0 = np.array(data['A0'].todense())\n",
        "X = data['X']\n",
        "N = len(A0[:,0])\n",
        "\n",
        "\n",
        "# Cora\n",
        "data=loadmat('/Datasets/cora.mat')\n",
        "A0 = data['A0']\n",
        "X = data['X']\n",
        "N = len(A0[:,0])\n",
        "\n",
        "\n",
        "# Synthetic data\n",
        "A0 = load_variable('/Datasets/syn/theta_syn')\n",
        "N = np.size(A0,0)\n",
        "X = load_variable('/Datasets/syn/ga_affine_bool')\n",
        "D = np.size(X,1)  \n",
        "c_true = load_variable('/Datasets/syn/c_syn')   \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amZ7-6ztbYU9"
      },
      "outputs": [],
      "source": [
        "beta1 = 1\n",
        "beta2 = 1\n",
        "max_iter = 1000\n",
        "obj_fn = []\n",
        "w = 0.1*np.ones((len(X[0,:]),2))\n",
        "c=np.ones((N,))\n",
        "Q = np.zeros(np.shape(X))\n",
        "for m in range (0,max_iter):   \n",
        "  #Update c---------------------------------------------------------------------\n",
        "    Q,c = UpdateC(X,Q,w,abs(A0),1e-4*np.ones((N,1)),c,\n",
        "                10**3,m=N/4,beta1=1) \n",
        "    print(\"c=\",c.T)\n",
        "\n",
        "  #Update w---------------------------------------------------------------------\n",
        "    Q,w = UpdateW(X,Q,c,beta1,beta2,10**3,1e-4*np.ones((len(X[0,:]),1)),w) #X,Q,c,beta1,beta2,,max_iter,rho_w,w_init\n",
        "    \n",
        "    obj_fn.append(sum(abs(A0)@c)+(sum(sum(X*np.log(Q+1e-100)))+sum(sum((np.ones(np.shape(X))-X)*np.log(np.ones(np.shape(X))-Q+1e-100))))-beta2*np.linalg.norm(w)**2)\n",
        "############--------------------------------------------------------------------\n",
        "    if (m>0):\n",
        "      if (abs(obj_fn[m]-obj_fn[m-1])<10**(-4)):\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}